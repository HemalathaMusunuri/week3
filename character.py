from nltk.tokenize import wordpunct_tokenize
text="i am learning AI"
a=list(text)
print("original text:",text)
print("character tokens:",a)
print("number of characters:",len(a))